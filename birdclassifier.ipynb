{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#datasci libraries\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n#tensorflow\nimport tensorflow as tf\nfrom tensorflow.python import keras\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Input, Add, Dense, Dropout, Activation, ZeroPadding2D, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, BatchNormalization\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.optimizers import Adam, RMSprop\n\n#visualization\nfrom matplotlib.pyplot import imshow\nimport cv2\n\n#misc\nimport os.path\nfrom pathlib import Path\nimport glob\nimport random\nfrom sklearn.metrics import classification_report","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-26T01:06:14.356729Z","iopub.execute_input":"2023-09-26T01:06:14.357157Z","iopub.status.idle":"2023-09-26T01:06:27.281122Z","shell.execute_reply.started":"2023-09-26T01:06:14.357121Z","shell.execute_reply":"2023-09-26T01:06:27.279776Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"The dataset already has a pretrained EfficientNet model but I want to make my own","metadata":{}},{"cell_type":"code","source":"os.listdir('/kaggle/input/100-bird-species')","metadata":{"execution":{"iopub.status.busy":"2023-09-24T19:39:41.812015Z","iopub.execute_input":"2023-09-24T19:39:41.813576Z","iopub.status.idle":"2023-09-24T19:39:41.833888Z","shell.execute_reply.started":"2023-09-24T19:39:41.813529Z","shell.execute_reply":"2023-09-24T19:39:41.832895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using some helper functions for deep learning from Github for fun","metadata":{}},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\nfrom helper_functions import plot_loss_curves, walk_through_dir","metadata":{"execution":{"iopub.status.busy":"2023-09-24T23:59:00.148802Z","iopub.execute_input":"2023-09-24T23:59:00.149312Z","iopub.status.idle":"2023-09-24T23:59:01.431150Z","shell.execute_reply.started":"2023-09-24T23:59:00.149255Z","shell.execute_reply":"2023-09-24T23:59:01.429881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data is split into 3 folders (train, validation, test), and within each folder, there are 525 subfolders for each species. The number of images per species is around 150 for training and 5 for validation and testing.","metadata":{}},{"cell_type":"code","source":"dataset = \"../input/100-bird-species/train\"\nwalk_through_dir(dataset)","metadata":{"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-24T19:40:56.176977Z","iopub.execute_input":"2023-09-24T19:40:56.177365Z","iopub.status.idle":"2023-09-24T19:41:15.620730Z","shell.execute_reply.started":"2023-09-24T19:40:56.177324Z","shell.execute_reply":"2023-09-24T19:41:15.619445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Will be using a batch size of 32 and image size of 224x224x3","metadata":{}},{"cell_type":"code","source":"train_path = '/kaggle/input/100-bird-species/train'\nval_path = '/kaggle/input/100-bird-species/valid'\ntest_path = '/kaggle/input/100-bird-species/test'\n\nbatch = 32\nimgres = (224, 224)","metadata":{"execution":{"iopub.status.busy":"2023-09-24T19:46:43.263843Z","iopub.execute_input":"2023-09-24T19:46:43.264220Z","iopub.status.idle":"2023-09-24T19:46:43.272871Z","shell.execute_reply.started":"2023-09-24T19:46:43.264190Z","shell.execute_reply":"2023-09-24T19:46:43.271676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Concatenating all files into a dataframe for visualization","metadata":{}},{"cell_type":"code","source":"image_dir = Path(dataset)\n\nfilepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png')) + list(image_dir.glob(r'**/*.png'))\n\nlabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n\nfilepaths = pd.Series(filepaths, name='Filepath').astype(str)\nlabels = pd.Series(labels, name='Label')\n\nimage_df = pd.concat([filepaths, labels], axis=1)\nprint(image_df.shape)\nimage_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-24T23:11:31.321325Z","iopub.execute_input":"2023-09-24T23:11:31.322428Z","iopub.status.idle":"2023-09-24T23:11:34.905888Z","shell.execute_reply.started":"2023-09-24T23:11:31.322355Z","shell.execute_reply":"2023-09-24T23:11:34.904921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Shows a sample of 16 random bird images","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(4, 4, figsize = (11, 11))\nfor i in range(4):\n    for j in range(4):\n        random_index = random.randint(0, len(image_df) - 1)\n        file_path = image_df.loc[random_index, 'Filepath']\n        label = image_df.loc[random_index, 'Label']\n        img = plt.imread(file_path)\n        axes[i, j].imshow(img)\n        axes[i, j].set_title(label)\n        axes[i, j].axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-24T19:41:24.559891Z","iopub.execute_input":"2023-09-24T19:41:24.560255Z","iopub.status.idle":"2023-09-24T19:41:26.320327Z","shell.execute_reply.started":"2023-09-24T19:41:24.560227Z","shell.execute_reply":"2023-09-24T19:41:26.319160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Rescale the RGB values to a range of [0, 1]","metadata":{}},{"cell_type":"code","source":"train_generator = ImageDataGenerator(rescale = 1./255)\nval_generator = ImageDataGenerator(rescale = 1./255)\ntest_generator = ImageDataGenerator(rescale = 1./255)","metadata":{"execution":{"iopub.status.busy":"2023-09-24T19:46:29.310489Z","iopub.execute_input":"2023-09-24T19:46:29.310870Z","iopub.status.idle":"2023-09-24T19:46:29.316541Z","shell.execute_reply.started":"2023-09-24T19:46:29.310840Z","shell.execute_reply":"2023-09-24T19:46:29.315448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Read train/val/test images straight from directory","metadata":{}},{"cell_type":"code","source":"train_images = train_generator.flow_from_directory(\n    train_path,\n    target_size=imgres,\n    class_mode='categorical',\n    batch_size=batch\n)\n\nval_images = val_generator.flow_from_directory(\n    val_path,\n    target_size=imgres,\n    class_mode='categorical',\n    batch_size=batch\n)\n\ntest_images = test_generator.flow_from_directory(\n    test_path,\n    target_size=imgres,\n    class_mode='categorical',\n    batch_size=batch,\n    shuffle = False\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-24T23:32:00.673101Z","iopub.execute_input":"2023-09-24T23:32:00.673531Z","iopub.status.idle":"2023-09-24T23:32:04.081520Z","shell.execute_reply.started":"2023-09-24T23:32:00.673495Z","shell.execute_reply":"2023-09-24T23:32:04.080593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using transfer learning to freeze the pretrained layers of Inception network and fine tune the rest. An Inception network works by having convolutional layers with different filter sizes in parallel to capture and combine features at different scales. It's great for image classification because it uses less parameters than a traditional deep CNN and can capture a diverse range of features to use in an image. Fun fact: it was named after Christopher Nolan's movie of the same name because of the quote \"We need to go deeper\", which is pretty much what it does -- go deeper.","metadata":{}},{"cell_type":"code","source":"inception = tf.keras.applications.InceptionV3(weights='imagenet',include_top=False,input_shape=(224,224,3))\ninception.trainable = True\nfor layer in inception.layers[:197]:\n    layer.trainable = False \nfor layer in inception.layers:\n    print(layer.name, '--', layer.trainable)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-09-24T23:41:30.457893Z","iopub.execute_input":"2023-09-24T23:41:30.458311Z","iopub.status.idle":"2023-09-24T23:41:33.492579Z","shell.execute_reply.started":"2023-09-24T23:41:30.458280Z","shell.execute_reply":"2023-09-24T23:41:33.491504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Make sure we know the shape of the last layer so we can add in our own stuff","metadata":{}},{"cell_type":"code","source":"last_layer = inception.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlayer_output = last_layer.output\n\nn_categories = len(os.listdir('/kaggle/input/100-bird-species/train'))\nprint(n_categories)","metadata":{"execution":{"iopub.status.busy":"2023-09-24T20:55:01.116072Z","iopub.execute_input":"2023-09-24T20:55:01.116503Z","iopub.status.idle":"2023-09-24T20:55:01.127503Z","shell.execute_reply.started":"2023-09-24T20:55:01.116463Z","shell.execute_reply":"2023-09-24T20:55:01.126321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Adding a flatten layer to transition from convolution to fully connected, a final hidden layer with 1024 nodes, and a dropout layer to prevent overfitting. Our output will be a 525-class softmax for each bird species.","metadata":{}},{"cell_type":"code","source":"x = Flatten()(layer_output)\nx = Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\nx = Dropout(0.4)(x)\nx = Dense(n_categories, activation='softmax')(x)\n\nmodel = Model(inputs=inception.inputs, outputs=x)\nmodel.compile(optimizer = Adam(learning_rate=0.0001), \n              loss = 'categorical_crossentropy', \n              metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-09-24T20:55:01.129125Z","iopub.execute_input":"2023-09-24T20:55:01.129565Z","iopub.status.idle":"2023-09-24T20:55:01.194335Z","shell.execute_reply.started":"2023-09-24T20:55:01.129530Z","shell.execute_reply":"2023-09-24T20:55:01.193381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using learning rate decay to gradually reduce step size to ensure we converge towards a more optimal solution as we get closer to our goal","metadata":{}},{"cell_type":"code","source":"def scheduler(epoch, lr):\n    if epoch < 10:\n        return lr\n    else:\n        return lr * tf.math.exp(-0.1)\n    \ncallback = tf.keras.callbacks.LearningRateScheduler(scheduler)","metadata":{"execution":{"iopub.status.busy":"2023-09-24T20:55:01.196751Z","iopub.execute_input":"2023-09-24T20:55:01.197125Z","iopub.status.idle":"2023-09-24T20:55:01.205522Z","shell.execute_reply.started":"2023-09-24T20:55:01.197092Z","shell.execute_reply":"2023-09-24T20:55:01.204417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training time! Not sure if 25 epochs was too many or too few, but I don't want to redo it and I'm not sure how to implement checkpoints in training yet. My computer went to sleep twice which is why those message rate warnings are there.","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n            train_images,\n            validation_data = val_images,\n            epochs = 25,\n            callbacks=[callback])","metadata":{"execution":{"iopub.status.busy":"2023-09-24T20:55:24.785668Z","iopub.execute_input":"2023-09-24T20:55:24.786076Z","iopub.status.idle":"2023-09-24T22:31:45.556429Z","shell.execute_reply.started":"2023-09-24T20:55:24.786039Z","shell.execute_reply":"2023-09-24T22:31:45.555310Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks like we had a bit of overfitting to the training set. Overall, I'm super happy with 99.6% for training and 94.93% for validation even though there's quite a bit of reduceable variance. Ways to reduce this could be data augmentation to get a bigger training set, early stopping to prevent overfitting, or maybe adding L2/dropout layers for regularization. Test accuracy stands even better at 97.07%, and I'll try uploading my own images of birds to the test set in a future project to see how that goes.","metadata":{}},{"cell_type":"code","source":"results = model.evaluate(test_images, verbose=0)\n\nprint(\"    Test Loss: {:.5f}\".format(results[0]))\nprint(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))","metadata":{"execution":{"iopub.status.busy":"2023-09-24T23:32:14.093350Z","iopub.execute_input":"2023-09-24T23:32:14.094356Z","iopub.status.idle":"2023-09-24T23:32:24.452648Z","shell.execute_reply.started":"2023-09-24T23:32:14.094308Z","shell.execute_reply":"2023-09-24T23:32:24.451611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cool graphs. Not sure why validation accuracy started so high.","metadata":{}},{"cell_type":"code","source":"accuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'b', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\n\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\n\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-24T22:32:24.928272Z","iopub.execute_input":"2023-09-24T22:32:24.929357Z","iopub.status.idle":"2023-09-24T22:32:25.511191Z","shell.execute_reply.started":"2023-09-24T22:32:24.929310Z","shell.execute_reply":"2023-09-24T22:32:25.510215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Taking a look at our predictions on the test set","metadata":{}},{"cell_type":"code","source":"pred = model.predict(test_images)\npred = np.argmax(pred,axis=1)\n\nlabels = (train_images.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npred = [labels[k] for k in pred]","metadata":{"execution":{"iopub.status.busy":"2023-09-24T23:32:30.119051Z","iopub.execute_input":"2023-09-24T23:32:30.119445Z","iopub.status.idle":"2023-09-24T23:32:35.909239Z","shell.execute_reply.started":"2023-09-24T23:32:30.119409Z","shell.execute_reply":"2023-09-24T23:32:35.908274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred[:20]","metadata":{"execution":{"iopub.status.busy":"2023-09-24T23:34:28.491457Z","iopub.execute_input":"2023-09-24T23:34:28.491878Z","iopub.status.idle":"2023-09-24T23:34:28.499590Z","shell.execute_reply.started":"2023-09-24T23:34:28.491833Z","shell.execute_reply":"2023-09-24T23:34:28.498571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Making a dataframe for the true labels of the test set so we can compare the predicted vs true labels","metadata":{}},{"cell_type":"code","source":"image_dir = Path(test_path)\n\nfilepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png')) + list(image_dir.glob(r'**/*.png'))\n\nlabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n\nfilepaths = pd.Series(filepaths, name='Filepath').astype(str)\nlabels = pd.Series(labels, name='Label')\n\ntest_df = pd.concat([filepaths, labels], axis=1)\ntest_df = test_df.sort_values(by='Filepath')\nprint(test_df.shape)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-24T23:36:34.741507Z","iopub.execute_input":"2023-09-24T23:36:34.742553Z","iopub.status.idle":"2023-09-24T23:36:36.605632Z","shell.execute_reply.started":"2023-09-24T23:36:34.742516Z","shell.execute_reply":"2023-09-24T23:36:36.604634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Green for correct prediction, red for incorrect. Way cooler visualization method than a classification report","metadata":{}},{"cell_type":"code","source":"random_index = np.random.randint(0, len(test_df) - 1, 15)\nfig, axes = plt.subplots(nrows=3, ncols=5, figsize=(25, 15),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(test_df.Filepath.iloc[random_index[i]]))\n    if test_df.Label.iloc[random_index[i]] == pred[random_index[i]]:\n        color = \"green\"\n    else:\n        color = \"red\"\n    ax.set_title(f\"True: {test_df.Label.iloc[random_index[i]]}\\nPredicted: {pred[random_index[i]]}\", color=color)\nplt.show()\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2023-09-24T23:36:49.434018Z","iopub.execute_input":"2023-09-24T23:36:49.434719Z","iopub.status.idle":"2023-09-24T23:36:51.446244Z","shell.execute_reply.started":"2023-09-24T23:36:49.434676Z","shell.execute_reply":"2023-09-24T23:36:51.445404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"But I'll do a classification report anyway. Not sure if 5 examples per species is enough, maybe I could try a bigger validation/test set in the future","metadata":{}},{"cell_type":"code","source":"y_test = list(test_df.Label)\nprint(classification_report(y_test, pred))","metadata":{"execution":{"iopub.status.busy":"2023-09-24T23:37:00.454837Z","iopub.execute_input":"2023-09-24T23:37:00.455211Z","iopub.status.idle":"2023-09-24T23:37:00.533012Z","shell.execute_reply.started":"2023-09-24T23:37:00.455181Z","shell.execute_reply":"2023-09-24T23:37:00.532064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And finally we save the model to use in the future. Hopefully TensorFlow doesn't bug out like last time so I can actually use the model I spent so long training again in the future.","metadata":{}},{"cell_type":"code","source":"model.save('inceptionv3_birdclassifier.h5')","metadata":{"execution":{"iopub.status.busy":"2023-09-24T23:39:02.779575Z","iopub.execute_input":"2023-09-24T23:39:02.779972Z","iopub.status.idle":"2023-09-24T23:39:06.651760Z","shell.execute_reply.started":"2023-09-24T23:39:02.779942Z","shell.execute_reply":"2023-09-24T23:39:06.650708Z"},"trusted":true},"execution_count":null,"outputs":[]}]}